{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the tutorial available in https://lava-nc.org/lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html, which explains the training of a simple feed-forward classifier on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import numpy as np\n",
    "import typing as ty\n",
    "\n",
    "# Import process level primitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "\n",
    "# Import MNIST dataset\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the Lava processes that will compose the feed-forward classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeInput(AbstractProcess):\n",
    "    \"\"\"Reads image data from the MNIST dataset and converts it to spikes.\n",
    "    The resulting spike rate is proportional to the pixel value.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vth: int,\n",
    "                 num_images: ty.Optional[int] = 25,\n",
    "                 num_steps_per_image: ty.Optional[int] = 128):\n",
    "        super().__init__()\n",
    "        shape = (784,)\n",
    "        self.spikes_out = OutPort(shape=shape)  # Input spikes to the classifier\n",
    "        self.label_out = OutPort(shape=(1,))  # Ground truth labels to OutputProc\n",
    "        self.num_images = Var(shape=(1,), init=num_images)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=num_steps_per_image)\n",
    "        self.input_img = Var(shape=shape)\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        self.v = Var(shape=shape, init=0)\n",
    "        self.vth = Var(shape=(1,), init=vth)\n",
    "\n",
    "\n",
    "class ImageClassifier(AbstractProcess):\n",
    "    \"\"\"A 3 layer feed-forward network with LIF and Dense Processes.\"\"\"\n",
    "\n",
    "    def __init__(self, trained_weights_path: str):\n",
    "        super().__init__()\n",
    "\n",
    "        # Using pre-trained weights and biases\n",
    "        real_path_trained_wgts = os.path.realpath(trained_weights_path)\n",
    "\n",
    "        wb_list = np.load(real_path_trained_wgts, encoding='latin1', allow_pickle=True)\n",
    "        w0 = wb_list[0].transpose().astype(np.int32)\n",
    "        w1 = wb_list[2].transpose().astype(np.int32)\n",
    "        w2 = wb_list[4].transpose().astype(np.int32)\n",
    "        b1 = wb_list[1].astype(np.int32)\n",
    "        b2 = wb_list[3].astype(np.int32)\n",
    "        b3 = wb_list[5].astype(np.int32)\n",
    "\n",
    "        self.spikes_in = InPort(shape=(w0.shape[1],))\n",
    "        self.spikes_out = OutPort(shape=(w2.shape[0],))\n",
    "        self.w_dense0 = Var(shape=w0.shape, init=w0)\n",
    "        self.b_lif1 = Var(shape=(w0.shape[0],), init=b1)\n",
    "        self.w_dense1 = Var(shape=w1.shape, init=w1)\n",
    "        self.b_lif2 = Var(shape=(w1.shape[0],), init=b2)\n",
    "        self.w_dense2 = Var(shape=w2.shape, init=w2)\n",
    "        self.b_output_lif = Var(shape=(w2.shape[0],), init=b3)\n",
    "\n",
    "        # Up-level currents and voltages of LIF Processes\n",
    "        # for resetting (see at the end of the tutorial)\n",
    "        self.lif1_u = Var(shape=(w0.shape[0],), init=0)\n",
    "        self.lif1_v = Var(shape=(w0.shape[0],), init=0)\n",
    "        self.lif2_u = Var(shape=(w1.shape[0],), init=0)\n",
    "        self.lif2_v = Var(shape=(w1.shape[0],), init=0)\n",
    "        self.oplif_u = Var(shape=(w2.shape[0],), init=0)\n",
    "        self.oplif_v = Var(shape=(w2.shape[0],), init=0)\n",
    "\n",
    "\n",
    "class OutputProcess(AbstractProcess):\n",
    "    \"\"\"Process to gather spikes from 10 output LIF neurons and interpret the\n",
    "    highest spiking rate as the classifier output\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        shape = (10,)\n",
    "        n_img = kwargs.pop('num_images', 25)\n",
    "        self.num_images = Var(shape=(1,), init=n_img)\n",
    "        self.spikes_in = InPort(shape=shape)\n",
    "        self.label_in = InPort(shape=(1,))\n",
    "        self.spikes_accum = Var(shape=shape)  # Accumulated spikes for classification\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=128)\n",
    "        self.pred_labels = Var(shape=(n_img,))\n",
    "        self.gt_labels = Var(shape=(n_img,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of process models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    vth: int = LavaPyType(int, int, precision=32)\n",
    "\n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.mnist_dataset = MnistDataset()\n",
    "        self.curr_img_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % self.num_steps_per_image == 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above\n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        img = self.mnist_dataset.images[self.curr_img_id]\n",
    "        self.ground_truth_label = self.mnist_dataset.labels[self.curr_img_id]\n",
    "        self.input_img = img.astype(np.int32) - 127\n",
    "        self.v = np.zeros(self.v.shape)\n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "        self.curr_img_id += 1\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        self.v[:] = self.v + self.input_img\n",
    "        s_out = self.v > self.vth\n",
    "        self.v[s_out] = 0  # reset voltage to 0 after a spike\n",
    "        self.spikes_out.send(s_out)\n",
    "\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "\n",
    "@implements(ImageClassifier)\n",
    "@requires(CPU)\n",
    "class PyImageClassifierModel(AbstractSubProcessModel):\n",
    "    def __init__(self, proc):\n",
    "        self.dense0 = Dense(weights=proc.w_dense0.init)\n",
    "        self.lif1 = LIF(shape=(64,), bias_mant=proc.b_lif1.init, vth=400,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense1 = Dense(weights=proc.w_dense1.init)\n",
    "        self.lif2 = LIF(shape=(64,), bias_mant=proc.b_lif2.init, vth=350,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense2 = Dense(weights=proc.w_dense2.init)\n",
    "        self.output_lif = LIF(shape=(10,), bias_mant=proc.b_output_lif.init,\n",
    "                              vth=1, dv=0, du=4095)\n",
    "\n",
    "        proc.spikes_in.connect(self.dense0.s_in)\n",
    "        self.dense0.a_out.connect(self.lif1.a_in)\n",
    "        self.lif1.s_out.connect(self.dense1.s_in)\n",
    "        self.dense1.a_out.connect(self.lif2.a_in)\n",
    "        self.lif2.s_out.connect(self.dense2.s_in)\n",
    "        self.dense2.a_out.connect(self.output_lif.a_in)\n",
    "        self.output_lif.s_out.connect(proc.spikes_out)\n",
    "\n",
    "        # Create aliases of SubProcess variables\n",
    "        proc.lif1_u.alias(self.lif1.u)\n",
    "        proc.lif1_v.alias(self.lif1.v)\n",
    "        proc.lif2_u.alias(self.lif2.u)\n",
    "        proc.lif2_v.alias(self.lif2.v)\n",
    "        proc.oplif_u.alias(self.output_lif.u)\n",
    "        proc.oplif_v.alias(self.output_lif.v)\n",
    "\n",
    "\n",
    "@implements(proc=OutputProcess, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutputProcessModel(PyLoihiProcessModel):\n",
    "    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "\n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.current_img_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % self.num_steps_per_image == 0 and \\\n",
    "                self.time_step > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above\n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        gt_label = self.label_in.recv()\n",
    "        pred_label = np.argmax(self.spikes_accum)\n",
    "        self.gt_labels[self.current_img_id] = gt_label\n",
    "        self.pred_labels[self.current_img_id] = pred_label\n",
    "        self.current_img_id += 1\n",
    "        self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        spk_in = self.spikes_in.recv()\n",
    "        self.spikes_accum = self.spikes_accum + spk_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 25\n",
    "num_steps_per_image = 128\n",
    "\n",
    "# Create Process instances\n",
    "spike_input = SpikeInput(vth=1,\n",
    "                         num_images=num_images,\n",
    "                         num_steps_per_image=num_steps_per_image)\n",
    "mnist_clf = ImageClassifier(\n",
    "    trained_weights_path=os.path.join('.', 'mnist_pretrained.npy'))\n",
    "output_proc = OutputProcess(num_images=num_images)\n",
    "\n",
    "# Connect Processes\n",
    "spike_input.spikes_out.connect(mnist_clf.spikes_in)\n",
    "mnist_clf.spikes_out.connect(output_proc.spikes_in)\n",
    "# Connect Input directly to Output for ground truth labels\n",
    "spike_input.label_out.connect(output_proc.label_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image: 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14403/3723212874.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.gt_labels[self.current_img_id] = gt_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image: 25\n",
      "Ground truth: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1]\n",
      "Predictions : [3 0 4 1 4 2 1 3 1 4 3 5 3 6 1 7 2 8 5 9 4 0 9 1 1]\n",
      "Accuracy    : 88.0\n"
     ]
    }
   ],
   "source": [
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "# Loop over all images\n",
    "for img_id in range(num_images):\n",
    "    print(f\"\\rCurrent image: {img_id+1}\", end=\"\")\n",
    "\n",
    "    # Run each image-inference for fixed number of steps\n",
    "    mnist_clf.run(\n",
    "        condition=RunSteps(num_steps=num_steps_per_image),\n",
    "        run_cfg=Loihi1SimCfg(select_sub_proc_model=True,\n",
    "                             select_tag='fixed_pt'))\n",
    "\n",
    "    # Reset internal neural state of LIF neurons\n",
    "    mnist_clf.lif1_u.set(np.zeros((64,), dtype=np.int32))\n",
    "    mnist_clf.lif1_v.set(np.zeros((64,), dtype=np.int32))\n",
    "    mnist_clf.lif2_u.set(np.zeros((64,), dtype=np.int32))\n",
    "    mnist_clf.lif2_v.set(np.zeros((64,), dtype=np.int32))\n",
    "    mnist_clf.oplif_u.set(np.zeros((10,), dtype=np.int32))\n",
    "    mnist_clf.oplif_v.set(np.zeros((10,), dtype=np.int32))\n",
    "\n",
    "# Gather ground truth and predictions before stopping exec\n",
    "ground_truth = output_proc.gt_labels.get().astype(np.int32)\n",
    "predictions = output_proc.pred_labels.get().astype(np.int32)\n",
    "\n",
    "# Stop the execution\n",
    "mnist_clf.stop()\n",
    "\n",
    "accuracy = np.sum(ground_truth==predictions)/ground_truth.size * 100\n",
    "\n",
    "print(f\"\\nGround truth: {ground_truth}\\n\"\n",
    "      f\"Predictions : {predictions}\\n\"\n",
    "      f\"Accuracy    : {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
